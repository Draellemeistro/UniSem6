## **How can an intermediary hardware device leveraging cloud components and machine learning be used to effectively protect systems against malicious USB devices?**

### What are the most common USB-borne attack vectors (e.g., malware, HID attacks) and how can they be mitigated using an external device without altering the USB protocol?

### How can computation-heavy tasks such as malware analysis be securely offloaded to the cloud while maintaining acceptable levels of latency and overhead? 

### What types of machine learning algorithms are most effective for detecting malicious USB device behavior, and how can they be implemented in this architecture?
##### Malware Classifier
Finding the best performing model mean going through the testing and evaluation of different malware classification models. The testing phase involved assessing the performance of various models on unseen data to determine their generalizability and robustness. To get a holistic overview of the how the models performed in comparison, we looked at the mean cross validation accuracy, test accuracy, and the ROC-AUC score. This gave us insight into each model's ability to generalize on training data, overall correctness and class separation ability. Looking mainly at the ROC-AUC and test accuracy as the most important factors? 
As seen in table \ref{tab:model_performances} most models performed very well with almost perfect ROC-AUC scores but Random Forrest was found to consistently deliver the best results. It was also made clear that simpler models such as Naive Bayes and Logistic Regression, underperformed significantly compared to the more complex models such as XGBoost and LightGBM. They showed strong performance, suggesting they could serve as competitive alternatives. 

##### Keystroke Injection Classifier
As a part of our device, we wanted to develop a way to detect keystroke injections. 
During the semester we had a course in machine learning. For this machine learning course, we did a mini machine learning project. We chose to use this mini project to develop a keystroke injection classifier for our semester project. 
For the mini project, we trained a model on two datasets. The first dataset contained data about how a human would write an essay and the second dataset was generated pseudo data to mimic malicious keystroke injections. We combined these into one file. From there we trained 14 different models and evaluated their results based on the ROC-AUC score, before saving the best model. Looking at the results, we noticed signs of overfitting. After the course and the exam, we reviewed our mini project and identified several issues that needed to be addressed. One significant error was the simultaneous normalization and standardization of the data, which was incorrect and introduced inconsistencies in our model's training process. Using normalization would compress the data too much leading to the loss of valuable data. As a result of this we decided to standardize the data, as it better suited our dataset. 
As we progressed our semester project we found that our needs and requirements for the injection classifier had changed, as a result of this we decided to take a step back and redo the process. 
In the mini project, our goal was predicting individual keystrokes, limiting us to the two features: hold time and flight time. We expanded the scope by introducing an analysis of virtual key code sequences in batches. This approach allowed us to detect potential "red flag" words or patterns that could indicate malicious intent, providing an extra dimension and ultimately, better predictions.